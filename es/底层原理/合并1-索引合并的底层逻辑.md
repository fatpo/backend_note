## 写在前面

我们都知道 es 会自动或者可以手动 merge，但其实不是很清楚底层的原理如何。

了解底层的 merge 策略和底层原理，可以更好的帮助我们使用 es 和减轻日常 es 运维压力。

等等，又是运维，为什么开发面试问运维知识，运维面试问开发知识？

# es 怎么写数据的
没看之前，盲猜就是：
```
先写到一个内存的 buffer（主要是能利用顺序 IO + 批量的高效），
再有个参数配置，几秒刷到磁盘（一般是三个配置：always，one_second, os，
分别是一直刷、每秒刷、看操作系统file page cache满了刷）。
```
以下是抄自文档（引用 1）：
```text
当我们往 ElasticSearch 写入数据时，数据是先写入 memory buffer，然后定时（默认每隔1s）将 memory buffer 中的数据写入一个新的 segment 文件中，
并进入 Filesystem cache（同时清空 memory buffer），这个过程就叫做 refresh；每个 Segment 事实上是一些倒排索引的集合， 
只有经历了 refresh 操作之后，数据才能变成可检索的。
```

这里我们就引出一个概念，es 数据每秒都刷到磁盘的文件中，这个文件就是 segment。

## segment 长什么样子

* 首先他是个文件，按照一定格式组织起来的文件。
* 每个 segment 是一个包含正排（空间占比90,95%）+ 倒排（空间占比5,10%）的完整索引文件。
* 每次搜索请求会把每个 segment 的倒排加载到内存空间，打分，再回流，将命中的文档号拿到正排中召回完整数据记录。

## segment 多会导致什么问题
* 每秒 commit 一次，这么看来一天要产生 86400 个 segment，每个 segment 都是一个文件，进程每操作一个文件都要消耗一个 fd（我依稀记得默认情况下，linux 一个进程能操控的句柄是 1024个？），服务器的句柄经得住这么消耗吗？
* 而且 es 在线服务会加载并搜索每一个 segment，segment 越多，搜索效率越低。

所以需要合并 segment。

## 合并 segment 大致流程是什么
* 1、开一个后台进程，定期 merge（默认是每秒一次）
* 2、将多个小 segment 合并到一个大的 segment，跳过那些被标记为删除的 segment，或者旧版本的 segment
* 3、合并完成后，然后将新的 segment 文件 flush 写入磁盘
* 4、然后创建一个新的 commit point 文件，标识所有新的 segment 文件，并排除掉旧的 segment 和已经被合并的小 segment
* 5、然后打开新 segment 文件用于搜索使用，等所有的检索请求都从小的 segment 转到 大 segment 上以后，删除旧的 segment 文件，这时候，索引里 segment 数量就下降了


# 原文搬运

* [Elasticsearch搜索引擎：ES的segment段合并原理](https://blog.csdn.net/a745233700/article/details/117953198)
* [Elasticsearch merge 你懂了吗？](https://cloud.tencent.com/developer/article/1846903)